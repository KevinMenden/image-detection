{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "data_path = \"/run/media/kevin/Volume/OpenImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Test Class\"\"\"\n",
    "    \n",
    "    def __init__(self, label_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(label_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Make some adjustments\n",
    "        self.labels.index = self.labels['ImageID']\n",
    "        self.labels = self.labels[self.labels['Confidence'] == 1]\n",
    "        self.label_names = np.sort(list(set(self.labels['LabelName'])))\n",
    "        self.images = list(set(self.labels['ImageID']))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Get an image\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        # Load image\n",
    "        img_id = self.images[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.images[idx]+\".jpg\")\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Create label vector\n",
    "        img_objects = np.array(self.labels.loc[img_id,]['LabelName'])\n",
    "        image_label = np.array([1 if x in img_objects else 0 for x in self.label_names])\n",
    "        \n",
    "        # Apply transform\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        image = np.asarray(image)\n",
    "        sample = {'image': image, 'label': image_label}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Scale((100, 100)),\n",
    "     transforms.Grayscale(3),\n",
    "     transforms.ToTensor()])\n",
    "\n",
    "root_dir = os.path.join(data_path, \"pics\")\n",
    "csv_path = os.path.join(data_path, \"subset_train_annots.csv\")\n",
    "dataset = ImageDataset(label_file = csv_path, root_dir = root_dir, transform=transform)\n",
    "sample = dataset[129]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601 classes\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(dataset.label_names)\n",
    "print(f\"{n_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(in_features=512, out_features=n_classes, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398079"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=6)\n",
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.000010\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=6)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "       \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        imgs = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
